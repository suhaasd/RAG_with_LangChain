{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e422476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typesense\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "client = typesense.Client({\n",
    "  'nodes': [{\n",
    "    'host': os.getenv('TYPESENSE_HOST_NAME'),  \n",
    "    'port': '443',      \n",
    "    'protocol': 'https'\n",
    "  }],\n",
    "  'api_key': os.getenv('TYPESENSE_API_KEY'),\n",
    "  'connection_timeout_seconds': 2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412078da",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_schema={\n",
    "    'name':'books',\n",
    "    'fields':[\n",
    "        {'name':'title', 'type':'string'},\n",
    "        {'name':'authors', 'type':'string[]', 'facet':True},\n",
    "        {'name':'publication_year', 'type':'int32', 'facet':True},\n",
    "        {'name':'ratings_count', 'type':'int32'},\n",
    "        {'name':'average_rating', 'type':'float'},\n",
    "    ],\n",
    "    'default_sorting_field':'ratings_count'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.collections.create(books_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29f69d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecation warning: Overrides is deprecated on v30+. Use client.curation_sets instead.\n",
      "Deprecation warning: The synonyms API (collections/{collection}/synonyms) is deprecated is removed on v30+. Use synonym sets (synonym_sets) instead.\n"
     ]
    }
   ],
   "source": [
    "with open('../data/json/books.jsonl', 'r', encoding='utf-8') as json1_file:\n",
    "    data=json1_file.read()\n",
    "    client.collections['books'].documents.import_(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb10811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'facet_counts': [],\n",
       " 'found': 1,\n",
       " 'hits': [{'document': {'authors': ['J.K. Rowling', ' Mary GrandPré'],\n",
       "    'average_rating': 4.44,\n",
       "    'id': '2',\n",
       "    'image_url': 'https://images.gr-assets.com/books/1474154022m/3.jpg',\n",
       "    'publication_year': 1997,\n",
       "    'ratings_count': 4602479,\n",
       "    'title': \"Harry Potter and the Philosopher's Stone\"},\n",
       "   'highlight': {'title': {'matched_tokens': ['Harry', 'Potter'],\n",
       "     'snippet': \"<mark>Harry</mark> <mark>Potter</mark> and the Philosopher's Stone\"}},\n",
       "   'highlights': [{'field': 'title',\n",
       "     'matched_tokens': ['Harry', 'Potter'],\n",
       "     'snippet': \"<mark>Harry</mark> <mark>Potter</mark> and the Philosopher's Stone\"}],\n",
       "   'text_match': 1157451471441102969,\n",
       "   'text_match_info': {'best_field_score': '2211897868289',\n",
       "    'best_field_weight': 15,\n",
       "    'fields_matched': 1,\n",
       "    'num_tokens_dropped': 0,\n",
       "    'score': '1157451471441102969',\n",
       "    'tokens_matched': 2,\n",
       "    'typo_prefix_score': 0}}],\n",
       " 'out_of': 9979,\n",
       " 'page': 1,\n",
       " 'request_params': {'collection_name': 'books',\n",
       "  'first_q': 'harry potter',\n",
       "  'per_page': 10,\n",
       "  'q': 'harry potter'},\n",
       " 'search_cutoff': False,\n",
       " 'search_time_ms': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_parameters={\n",
    "    'q':\"harry potter\",\n",
    "    'query_by':'title,authors',\n",
    "    'filter_by':'publication_year:<1998',\n",
    "    'sort_by':'publication_year:desc'\n",
    "}\n",
    "\n",
    "client.collections['books'].documents.search(search_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5d9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmsuhaas\\Downloads\\RAG_with_LangChain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Typesense\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08723829",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d55785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 3 pdf files to process\n",
      "\n",
      "Processing: code generation using LLMs (compressed).pdf\n",
      "loaded 70 pages\n",
      "\n",
      "Processing: flashfill.pdf\n",
      "loaded 30 pages\n",
      "\n",
      "Processing: Systematic mapping study of template based code generation.pdf\n",
      "loaded 20 pages\n",
      "\n",
      "Total document pages loaded: 120\n"
     ]
    }
   ],
   "source": [
    "#read all pdfs inside directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    all_documents=[]\n",
    "    pdf_dir=Path(pdf_directory)\n",
    "    pdf_files=list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    print(f\"found {len(pdf_files)} pdf files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader=PyMuPDFLoader(str(pdf_file))\n",
    "            documents=loader.load()\n",
    "\n",
    "            #adding more info to the metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file']=pdf_file.name\n",
    "                doc.metadata['file_type']='pdf'\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"loaded {len(documents)} pages\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error: {e}\")\n",
    "\n",
    "    print(f\"\\nTotal document pages loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "all_pdf_documents=process_all_pdfs(\"../data/pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bddc300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 120 document pages into 644 chunks\n"
     ]
    }
   ],
   "source": [
    "#split text into chunks\n",
    "#sliding window chunking\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\",\" \",\"\"]\n",
    "    )\n",
    "    split_docs=text_splitter.split_documents(documents)\n",
    "    print(f\"split {len(documents)} document pages into {len(split_docs)} chunks\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "chunks=split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba867425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmsuhaas\\Downloads\\RAG_with_LangChain\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dmsuhaas\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6dfbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch=Typesense.from_documents(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    typesense_client_params={\n",
    "        'host': os.getenv('TYPESENSE_HOST_NAME'),  \n",
    "        'port': '443',      \n",
    "        'protocol': 'https',\n",
    "        'typesense_api_key': os.getenv('TYPESENSE_API_KEY'),\n",
    "        'typesense_collection_name':'pdf',\n",
    "        'connection_timeout_seconds': 60\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ae61fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "researchers in establishing a comprehensive, up-to-date, and advanced understanding of LLMs for\n",
      "code generation. This includes discussing various aspects of this rapidly evolving domain, such as\n",
      "data curation, latest advancements, performance evaluation, ethical and environmental implications,\n",
      "and real-world applications. A historical overview of the evolution of LLMs for code generation is\n",
      "J. ACM, Vol. 37, No. 4, Article 1. Publication date: August 2018.\n"
     ]
    }
   ],
   "source": [
    "query=\"how is LLM used for code generation\"\n",
    "found_docs=docsearch.similarity_search(query)\n",
    "print(found_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88377c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 8, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='researchers in establishing a comprehensive, up-to-date, and advanced understanding of LLMs for\\ncode generation. This includes discussing various aspects of this rapidly evolving domain, such as\\ndata curation, latest advancements, performance evaluation, ethical and environmental implications,\\nand real-world applications. A historical overview of the evolution of LLMs for code generation is\\nJ. ACM, Vol. 37, No. 4, Article 1. Publication date: August 2018.'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 54, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='offer an empirical comparison using the widely recognized HumanEval, MBPP, and the more\\npractical and challenging BigCodeBench benchmarks to highlight the progressive enhancements\\nin LLM capabilities for code generation. Critical challenges and promising opportunities regarding\\nthe gap between academia and practical development are also identified for future investigation.\\nFurthermore, we have established a dedicated resource website to continuously document and\\ndisseminate the most recent advances in the field. We hope this survey can contribute to a compre-\\nhensive and systematic overview of LLM for code generation and promote its thriving evolution.\\nWe optimistically believe that LLM will ultimately change all aspects of coding and automatically\\nwrite safe, helpful, accurate, trustworthy, and controllable code, like professional programmers,\\nand even solve coding problems that currently cannot be solved by humans.\\nREFERENCES'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 13, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='capture the breadth of advancements in LLMs for code generation, we conducted a distribution\\nanalysis of the research topics covered in the included papers, as shown at the bottom of Figure 4.\\nWe observe that the development of LLMs for code generation closely aligns with broader trends\\nin general-purpose LLM research. Notably, the most prevalent research topics are Pre-training and\\nFoundation Models (21.5%), Prompting (11.8%), and Evaluation and Benchmarks (24.1%). These\\nareas hold significant promise for enhancing, refining, and evaluating LLM-driven code generation.\\n4\\nTAXONOMY\\nThe recent surge in the development of LLMs has led to a significant number of these models\\nbeing repurposed for code generation task through continual pre-training or fine-tuning. This\\ntrend is particularly observable in the realm of open-source models. For instance, Meta AI initially\\nmade the LLaMA [252] model publicly available, which was followed by the release of Code Llama'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 8, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='generation task. While the adaptation of LLMs for code generation essentially follows the evolution\\nof LLMs, this evolution encompasses a broad spectrum of research directions and advancements.\\nFor software engineering (SE) researchers, it can be challenging and time-consuming to fully grasp\\nthe comprehensive research landscape of LLMs and their adaptation to code generation. RQ1 aims\\nto propose a taxonomy that serves as a comprehensive reference for researchers, enabling them to\\nquickly familiarize themselves with the state-of-the-art in this dynamic field and identify specific\\nresearch problems and directions of interest.\\nRQ2: What are the key insights into LLMs for code generation? RQ2 seeks to assist\\nresearchers in establishing a comprehensive, up-to-date, and advanced understanding of LLMs for\\ncode generation. This includes discussing various aspects of this rapidly evolving domain, such as'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 9, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='benchmarks, as well as the more practical and challenging BigCodeBench benchmark, to highlight\\nthe progressive enhancements in LLM capabilities for code generation. RQ2 offers an in-depth\\nanalysis of critical insights related to LLMs for code generation.\\nRQ3: What are the critical challenges and promising research opportunities in LLMs for\\ncode generation? Despite the revolutionary impact of LLMs on the paradigm of code generation\\nand their remarkable performance, numerous challenges remain unaddressed. These challenges\\nprimarily stem from the gap between academic research and practical development. For instance,\\nwhile the HumanEval benchmark is established as a de facto standard for evaluating the coding\\nproficiency of LLMs in academia, it has been shown that this evaluation does not adequately reflect\\npractical development scenarios [68, 72, 123, 162]. RQ3 aims to identify critical challenges and'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 13, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='1:14\\nJuyong Jiang, Fan Wang, Jiasi Shen, Sungju Kim, and Sunghun Kim\\nunderstandable given the emerging nature of this field, with many works being recent and pending\\nformal submission. Despite the absence of peer review on arXiv, our quality assessment process\\nensures that only high-quality papers are included, thereby maintaining the integrity of this survey.\\nFurthermore, the annual trend in the number of collected papers indicates nearly exponential\\ngrowth in the field. From a single paper in the period 2018 to 2020, the numbers increased to 6 in\\n2021, 11 in 2022, 75 in 2023, and 140 in 2024. This trend reflects growing interest and attention\\nin this research area, with expectations for continued expansion in the future. Additionally, to\\ncapture the breadth of advancements in LLMs for code generation, we conducted a distribution\\nanalysis of the research topics covered in the included papers, as shown at the bottom of Figure 4.'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 13, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='for code-related tasks, there has been a proliferation of models specifically engineered for code\\ngeneration. Notable examples include StarCoder [147], OctoCoder [187], and CodeGen [193]. These\\nmodels underscore the trend of LLMs being developed with a focus on code generation.\\nRecognizing the importance of these developments, we conduct a thorough analysis of selected\\npapers on LLMs for code generation, sourced from widely used scientific databases as mentioned\\nin Section 3. Based on this analysis, we propose a taxonomy that categorizes and evaluates the\\nlatest advancements in LLMs for code generation. This taxonomy, depicted in Figure 6, serves as a\\ncomprehensive reference for researchers seeking to quickly familiarize themselves with the state-\\nof-the-art in this dynamic field. It is important to highlight that the category of recent advances\\nemphasizes the core techniques used in the current state-of-the-art code LLMs.'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 15, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='OpenDevin[199], SWE-agent[124], L2MAC[98], OpenDevin CodeAct 1.0[287]\\nEvaluation\\n(Sec. 5.10)\\nMetrics\\nExact Match, BLEU[203], ROUGE[156], METEOR[23], CodeBLEU[221], pass@k[48]\\nn@k[151], test case average[95], execution accuracy[218], pass@t[195], perplexity[116]\\nHuman\\nEvaluation\\nCodePlan[22], RepoFusion[239], CodeBLEU[221]\\nLLM-as-a-Judge\\nAlpacaEval[148], MT-bench[320], ICE-Score[332]\\nCode LLMs\\nAlignment\\n(Sec. 5.10.3)\\nGreen[235, 277], Responsibility[168, 292], Efficiency[293], Safety[8, 9, 77, 91, 231, 294, 302], Trustworthiness[120, 202]\\nApplication\\n(Sec. 5.12)\\nGitHub Copilot[48], CodeGeeX[321], CodeWhisperer[12], Codeium[60], CodeArts Snap[234], TabNine[246], Replit[222]\\nFig. 6. Taxonomy of LLMs for code generation.\\nJ. ACM, Vol. 37, No. 4, Article 1. Publication date: August 2018.'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 10, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='and questions, and to eliminate irrelevant studies.\\nInclusion Criteria. A paper will be included if it meets any of the following criteria:\\n• It is available in full text.\\n• It presents a dataset or benchmark specifically designed for code generation with LLMs.\\n• It explores specific LLM techniques, such as pre-training or instruction tuning, for code\\ngeneration.\\n• It provides an empirical study or evaluation related to the use of LLMs for code generation.\\n• It discusses the ethical considerations and environmental impact of deploying LLMs for code\\ngeneration.\\n• It proposes tools or applications powered by LLMs for code generation.\\nExclusion Criteria. Conversely, papers will be excluded if they meet any of the following\\nconditions:\\n• They are not written in English.\\n• They are found in books, theses, monographs, keynotes, panels, or venues (excluding arXiv)\\nthat do not undergo a full peer-review process.'),\n",
       " Document(metadata={'author': '', 'creationDate': 'D:20241112015859Z', 'creationdate': '2024-11-12T01:58:59+00:00', 'creator': 'LaTeX with acmart 2021/05/01 v1.78 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'file_path': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'file_type': 'pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20241112015859Z', 'moddate': '2024-11-12T01:58:59+00:00', 'page': 14, 'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\data\\\\pdf\\\\code generation using LLMs (compressed).pdf', 'source_file': 'code generation using LLMs (compressed).pdf', 'subject': '-  General and reference  ->  Surveys and overviews.-  Software and its engineering  ->  Software development techniques.-  Computing methodologies  ->  Artificial intelligence.', 'title': 'A Survey on Large Language Models for Code Generation', 'total_pages': 70, 'trapped': ''}, page_content='agents. Section 5.10 discusses various evaluation strategies and offer an empirical comparison using\\nthe widely recognized HumanEval, MBPP, and the more practical and challenging BigCodeBench\\nbenchmarks to highlight the progressive enhancements in LLM capabilities for code generation.\\nFurthermore, the ethical implications and the environmental impact of using LLMs for code\\ngeneration are discussed in Section 5.11, aiming to establish a trustworthiness, responsibility, safety,\\nefficiency, and green of LLM for code generation. Lastly, Section 5.12 will provide insights into some\\nof the practical applications that leverage LLMs for code generation, demonstrating the real-world\\nimpact of these sophisticated models. Through this comprehensive exploration, we aim to highlight\\nthe significance and potential of LLMs within the domain of automated code generation.\\n5.1\\nData Curation & Processing\\nThe exceptional performance of LLMs can be attributed to their training on large-scale and diverse')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=docsearch.as_retriever()\n",
    "query=\"how is LLM used for code generation\"\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03ba776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, retriever, llm, top_k=6):\n",
    "    #retrieve the context\n",
    "    results = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question\"\n",
    "    \n",
    "    #generate a response using gemini/groq\n",
    "    prompt_template = \"\"\"You are an expert Computer Science research assistant. \n",
    "Your task is to answer the question based STRICTLY on the provided context.\n",
    "\n",
    "Guidelines:\n",
    "1. **Be Precise**: Use technical terminology found in the context.\n",
    "2. **Structure**: If the answer has multiple parts, use bullet points.\n",
    "3. **No Hallucination**: If the context does not contain the answer, say \"I cannot find the answer in the provided documents.\" Do not make up information.\n",
    "4. **Synthesis**: If the answer is split across multiple chunks, combine them into a coherent explanation.\n",
    "\n",
    "----------------\n",
    "Context:\n",
    "{context}\n",
    "----------------\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    final_prompt = prompt_template.format(context=context, query=query)\n",
    "    response=llm.invoke(final_prompt)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea88da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The characteristics of template-based code generation (TBCG) can be explained in detail as follows:\\n\\n* **Template style**: TBCG can be classified into different template styles, including:\\n\\t+ Output-based style: This is the most common style, where the final output target text drives the development of the template. The template has a static part and a dynamic part embedded with splices of meta-code that encode the generation logic.\\n\\t+ Rule-based style: This style puts the focus of the template on computing the dynamic part with the static part being implicit. The template lists declarative production rules that are applied on-demand by the template engine to obtain the final target output.\\n* **Input type**: TBCG characterizes the language of the design-time input that is necessary to develop templates. The run-time input is an instance that conforms to it. The input type can be a general-purpose modeling language, which is reusable across different domains.\\n* **Template components**: A template in TBCG consists of four components:\\n\\t+ Data: The input data that is used to generate the output.\\n\\t+ Template: The abstract and generalized representation of the textual output.\\n\\t+ Output: The textual artifact, such as source code, that is generated by the template engine.\\n\\t+ Meta-information: The design-time input that defines the meta-information which the run-time input conforms to.\\n* **Template execution**: The template engine executes the template by computing the dynamic part and replacing meta-codes by static text according to the run-time input.\\n* **Advantages**: TBCG has several advantages, including:\\n\\t+ Reduced user effort: The user has fewer lines to write, as specifications are shorter than the program that implements them.\\n\\t+ Easier to write and understand: Specifications are closer to the application and domain concepts, making them easier to write and understand.\\n\\t+ Less error-prone: Writing specifications is less error-prone than writing the program directly, as the expert is the one who writes the specification.\\n* **Relationship with MDE**: TBCG is closely related to Model-Driven Engineering (MDE), as both emphasize abstraction and automation. Many code generation tools have come out of the MDE community, and TBCG is a popular technique in MDE.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer=rag(\"What are the characteristics of template-based code generation? Explain in detail.\", retriever, llm)\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_with_LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
